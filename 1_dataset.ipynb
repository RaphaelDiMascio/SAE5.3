{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9f35df",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089bbe3",
   "metadata": {},
   "source": [
    "## Création du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0183880",
   "metadata": {},
   "source": [
    "Le code suivant permet de créer un **dataset** d'images que vous utiliserez dans votre projet de **reconnaissance faciale**. Ce dataset contiendra des images de vous-même associées à votre nom ainsi que des images d'autres personnes (par exemple vos camarades) associées à leurs noms. **À chaque fois que vos relancez le code ci-dessous, votre caméra capture 10 images de la personne qui se trouve devant vootre PC et ajoute ces dernières à votre dataset.** \n",
    "\n",
    "Le code effectue les opérations suivantes. Premièrement, on lit le flux vidéo de votre caméra et on détecte automatiquement les visages dans chaque image de ce flux en utilisant le **classificateur en cascade de Haar (Haar cascade classifier)** de la librairie `OpenCV`. \n",
    "\n",
    "Plus précisément, tant que la variable `ret` est vraie, indiquant que le flux vidéo est lu correctement, pour chaque image capturée par la caméras, on effectue les opérations suivantes:\n",
    "1. on convertit l'image en niveaux de gris;\n",
    "2. on détecte les coordonnées du visage en utilisant le classificateur en cascade de Haar;\n",
    "3. on recadre la région du visage et la redimensionne en $50 \\times 50$ pixels;\n",
    "4. on ajoute l'image du visage redimensionné à la liste `donnees_visage`, à chaque intervalle de $10$ images.\n",
    "\n",
    "Une fois que $10$ images de votre visage ont été collecteés, ou si l'utilisateur appuye sur la touche `Esc`, on met fin à la boucle et enregistre les images dans la liste `donnees_visage` sous forme d'un tableau `NumPy`.\n",
    "\n",
    "Par la suite, l'existence des fichiers `noms.pkl` et `visages.pkl` est vérifiée. S'ils n'existent pas, de nouveaux fichiers sont créés, la variable `nom` est enregistrée dans `noms.pkl` et les données de visage sont enregistrées dans `visages.pkl`. Si ces fichiers existent déjà, le code charge les données existantes, ajoute les nouvelles données de visage et noms, et les réenregistre le tout dans ces fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== #\n",
    "# Variables globales #\n",
    "# ================== #\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")         # création d'un répertoire data\n",
    "\n",
    "nb_images_collectees = 30    # nombre d'image que vous voulez collecter\n",
    "\n",
    "donnees_visage = []\n",
    "\n",
    "camera = cv2.VideoCapture(0) # 0 pour 'built-in' caméra, 1 pour caméra externe\n",
    "\n",
    "cascade_visage = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Assurez-vous que le classificateur de cascade des yeux est chargé correctement\n",
    "if cascade_visage.empty():\n",
    "    print(\"Erreur: Le classificateur de cascade n'a pas été chargé correctement.\")\n",
    "else:\n",
    "    print(\"Le classificateur de cascade a été chargé avec succès.\")\n",
    "\n",
    "\n",
    "# =============================== #\n",
    "# Capture des data: nom et images #\n",
    "# =============================== #\n",
    "nom = input(\"Entrez votre nom: \")\n",
    "\n",
    "ret = True\n",
    "i = 0\n",
    "\n",
    "while(ret):\n",
    "    \n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        \n",
    "        gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        coordonnees_visage = cascade_visage.detectMultiScale(gris, 1.3, 4)\n",
    "\n",
    "        for (a, b, w, h) in coordonnees_visage:\n",
    "            \n",
    "            visages = frame[b:b+h, a:a+w, :]\n",
    "            visages_redimensionnes = cv2.resize(visages, (50, 50))\n",
    "            \n",
    "            if i % nb_images_collectees == 0 and len(donnees_visage) < nb_images_collectees:\n",
    "                \n",
    "                donnees_visage.append(visages_redimensionnes)\n",
    "                \n",
    "            cv2.rectangle(frame, (a, b), (a+w, b+h), (255, 0, 0), 2)\n",
    "            \n",
    "        i += 1\n",
    "\n",
    "        cv2.imshow('Visages', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27 or len(donnees_visage) >= nb_images_collectees:\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        \n",
    "        print('erreur')\n",
    "        break\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "\n",
    "donnees_visage = np.asarray(donnees_visage)\n",
    "# donnees_visage = donnees_visage.reshape(10, -1)\n",
    "\n",
    "\n",
    "# ====================================== #\n",
    "# Enregistrement des data: nom et images #\n",
    "# ====================================== #\n",
    "if 'noms.pkl' not in os.listdir('data/'):\n",
    "    \n",
    "    noms = [nom] * nb_images_collectees\n",
    "    with open('data/noms.pkl', 'wb') as file:\n",
    "        pickle.dump(noms, file)\n",
    "else:\n",
    "    \n",
    "    with open('data/noms.pkl', 'rb') as file:\n",
    "        noms = pickle.load(file)\n",
    "\n",
    "    noms = noms + [nom] * nb_images_collectees\n",
    "    with open('data/noms.pkl', 'wb') as file:\n",
    "        pickle.dump(noms, file)\n",
    "\n",
    "\n",
    "if 'visages.pkl' not in os.listdir('data/'):\n",
    "    \n",
    "    with open('data/visages.pkl', 'wb') as w:\n",
    "        pickle.dump(donnees_visage, w)\n",
    "else:\n",
    "    \n",
    "    with open('data/visages.pkl', 'rb') as w:\n",
    "        visages = pickle.load(w)\n",
    "\n",
    "    visages = np.append(visages, donnees_visage, axis=0)\n",
    "    with open('data/visages.pkl', 'wb') as w:\n",
    "        pickle.dump(visages, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bec3e0",
   "metadata": {},
   "source": [
    "## Visualisation du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df3d2c",
   "metadata": {},
   "source": [
    "Le instructions suivantes permettent de loader votre dataset et de comprendre comment sont stockées les data.\n",
    "\n",
    "Prêtez attention aux types de vos data, en particulier à la dimension de vos images, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/noms.pkl\", \"rb\") as fh:\n",
    "    noms = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/visages.pkl\", \"rb\") as fh:\n",
    "    visages = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dab6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8436555",
   "metadata": {},
   "outputs": [],
   "source": [
    "visages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef19a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = visages[0]\n",
    "sample_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3539263",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_1, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4aaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2 = visages[5]\n",
    "sample_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed489bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_2, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "500ebf2854cb8a11",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
